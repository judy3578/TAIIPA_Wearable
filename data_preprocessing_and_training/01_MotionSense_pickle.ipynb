{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MotionSense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset  \n",
    "https://github.com/mmalekzadeh/motion-sense\n",
    "\n",
    "reference  \n",
    "https://www.kaggle.com/caspitush/activity-classification-gbc-fourier-transform\n",
    "\n",
    "6 activities collected from 24 participants  \n",
    "using smartphone sensors  \n",
    "sampling rate : 50Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-436nawvk because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "import pydot\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "#plt.rcParams['figure.figsize'] = (6,4) # Make the figures a bit bigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1b2c6893cf4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import socket\n",
    "hostname = socket.gethostname()\n",
    "print(hostname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(class_number, total_classes):\n",
    "    one_hot = np.zeros(total_classes)\n",
    "    one_hot[class_number] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirout = 'out'\n",
    "if not os.path.exists(dirout):\n",
    "    os.makedirs(dirout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../Dataset/03_MotionSense_Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = [\"down_stairs\",\"up_stairs\", \"walking\", \"jogging\", \"standing\", \"sitting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_infos():\n",
    "    dss = pd.read_csv(\"{}/data_subjects_info.csv\".format(data_loc))\n",
    "    print(\"[INFO] -- Data subjects' information is imported.\")\n",
    "    return dss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_types(data_types=[\"userAcceleration\"]):\n",
    "    dt_list = []\n",
    "    for t in data_types:\n",
    "        if t != \"attitude\":\n",
    "            dt_list.append([t+\".x\",t+\".y\",t+\".z\"])\n",
    "        else:\n",
    "            dt_list.append([t+\".roll\", t+\".pitch\", t+\".yaw\"])\n",
    "\n",
    "    return dt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT_LABELS = [\"dws\",\"ups\", \"wlk\", \"jog\", \"std\", \"sit\"]\n",
    "\n",
    "TRIAL_CODES = {\n",
    "    ACT_LABELS[0]:[1,2,11],\n",
    "    ACT_LABELS[1]:[3,4,12],\n",
    "    ACT_LABELS[2]:[7,8,15],\n",
    "    ACT_LABELS[3]:[9,16],\n",
    "    ACT_LABELS[4]:[6,14],\n",
    "    ACT_LABELS[5]:[5,13]\n",
    "}\n",
    "\n",
    "feature_name = ['acc_x', 'acc_y', 'acc_z',  'ang_x', 'ang_y', 'ang_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Selected sensor data types: ['userAcceleration', 'rotationRate']\n",
      "[INFO] -- Selected activites: ['dws', 'ups', 'wlk', 'jog', 'std', 'sit']\n"
     ]
    }
   ],
   "source": [
    "sdt = [\"userAcceleration\", \"rotationRate\"]\n",
    "print(\"[INFO] -- Selected sensor data types: \"+str(sdt))\n",
    "act_labels = ACT_LABELS [0:6]\n",
    "print(\"[INFO] -- Selected activites: \"+str(act_labels))    \n",
    "trial_codes = [TRIAL_CODES[act] for act in act_labels]\n",
    "dt_list = set_data_types(sdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_time_series(dt_list, act_labels, trial_codes, mode=\"mag\", labeled=True):\n",
    "    num_data_cols = len(dt_list) if mode == \"mag\" else len(dt_list*3)\n",
    "\n",
    "    if labeled:\n",
    "        dataset = np.zeros((0,num_data_cols+7)) # \"7\" --> [act, code, weight, height, age, gender, trial] \n",
    "    else:\n",
    "        dataset = np.zeros((0,num_data_cols))\n",
    "        \n",
    "    ds_list = get_ds_infos()\n",
    "    \n",
    "    print(\"[INFO] -- Creating Time-Series\")\n",
    "    for sub_id in ds_list[\"code\"]:\n",
    "        for act_id, act in enumerate(act_labels):\n",
    "            for trial in trial_codes[act_id]:\n",
    "                fname = '../Dataset/03_MotionSense_Dataset/'+act+'_'+str(trial)+'/sub_'+str(int(sub_id))+'.csv'\n",
    "                raw_data = pd.read_csv(fname)\n",
    "                raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "                vals = np.zeros((len(raw_data), num_data_cols))\n",
    "                for x_id, axes in enumerate(dt_list):\n",
    "                    if mode == \"mag\":\n",
    "                        vals[:,x_id] = (raw_data[axes]**2).sum(axis=1)**0.5        \n",
    "                    else:\n",
    "                        vals[:,x_id*3:(x_id+1)*3] = raw_data[axes].values\n",
    "                    vals = vals[:,:num_data_cols]\n",
    "                if labeled:\n",
    "                    lbls = np.array([[act_id,\n",
    "                            sub_id-1,\n",
    "                            ds_list[\"weight\"][sub_id-1],\n",
    "                            ds_list[\"height\"][sub_id-1],\n",
    "                            ds_list[\"age\"][sub_id-1],\n",
    "                            ds_list[\"gender\"][sub_id-1],\n",
    "                            trial          \n",
    "                           ]]*len(raw_data))\n",
    "                    vals = np.concatenate((vals, lbls), axis=1)\n",
    "                dataset = np.append(dataset,vals, axis=0)\n",
    "    cols = []\n",
    "    for axes in dt_list:\n",
    "        if mode == \"mag\":\n",
    "            cols += [str(axes[0][:-2])]\n",
    "        else:\n",
    "            cols += axes\n",
    "            \n",
    "    if labeled:\n",
    "        cols += [\"act\", \"id\", \"weight\", \"height\", \"age\", \"gender\", \"trial\"]\n",
    "    \n",
    "    dataset = pd.DataFrame(data=dataset, columns=cols)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] -- Data subjects' information is imported.\n",
      "[INFO] -- Creating Time-Series\n"
     ]
    }
   ],
   "source": [
    "dataset = creat_time_series(dt_list, act_labels, trial_codes, mode=\"raw\", labeled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "act 는 동작을 뜻하고, id는 사람을 뜻한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userAcceleration.x</th>\n",
       "      <th>userAcceleration.y</th>\n",
       "      <th>userAcceleration.z</th>\n",
       "      <th>rotationRate.x</th>\n",
       "      <th>rotationRate.y</th>\n",
       "      <th>rotationRate.z</th>\n",
       "      <th>act</th>\n",
       "      <th>id</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.294894</td>\n",
       "      <td>-0.184493</td>\n",
       "      <td>0.377542</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219405</td>\n",
       "      <td>0.035846</td>\n",
       "      <td>0.114866</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.134701</td>\n",
       "      <td>-0.167808</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.008389</td>\n",
       "      <td>0.136788</td>\n",
       "      <td>0.094958</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199441</td>\n",
       "      <td>0.353996</td>\n",
       "      <td>-0.044299</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412860</th>\n",
       "      <td>0.000789</td>\n",
       "      <td>-0.005937</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>-0.001312</td>\n",
       "      <td>-0.011512</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412861</th>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.022169</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412862</th>\n",
       "      <td>-0.000486</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>-0.012616</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412863</th>\n",
       "      <td>0.000311</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>-0.003029</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412864</th>\n",
       "      <td>0.001357</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1412865 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userAcceleration.x  userAcceleration.y  userAcceleration.z  \\\n",
       "0                  0.294894           -0.184493            0.377542   \n",
       "1                  0.219405            0.035846            0.114866   \n",
       "2                  0.010714            0.134701           -0.167808   \n",
       "3                 -0.008389            0.136788            0.094958   \n",
       "4                  0.199441            0.353996           -0.044299   \n",
       "...                     ...                 ...                 ...   \n",
       "1412860            0.000789           -0.005937           -0.004355   \n",
       "1412861           -0.000409           -0.000608            0.000098   \n",
       "1412862           -0.000486            0.000711            0.002045   \n",
       "1412863            0.000311           -0.003395            0.004746   \n",
       "1412864            0.001357           -0.004510            0.004161   \n",
       "\n",
       "         rotationRate.x  rotationRate.y  rotationRate.z  act    id  weight  \\\n",
       "0              0.316738        0.778180        1.082764  0.0   0.0   102.0   \n",
       "1              0.842032        0.424446        0.643574  0.0   0.0   102.0   \n",
       "2             -0.138143       -0.040741        0.343563  0.0   0.0   102.0   \n",
       "3             -0.025005       -1.048717        0.035860  0.0   0.0   102.0   \n",
       "4              0.114253       -0.912890        0.047341  0.0   0.0   102.0   \n",
       "...                 ...             ...             ...  ...   ...     ...   \n",
       "1412860       -0.001312       -0.011512        0.001284  5.0  23.0    74.0   \n",
       "1412861       -0.000293       -0.022169        0.001305  5.0  23.0    74.0   \n",
       "1412862        0.007208       -0.012616        0.003482  5.0  23.0    74.0   \n",
       "1412863        0.006180       -0.003029        0.004531  5.0  23.0    74.0   \n",
       "1412864        0.006227        0.012927        0.008797  5.0  23.0    74.0   \n",
       "\n",
       "         height   age  gender  trial  \n",
       "0         188.0  46.0     1.0    1.0  \n",
       "1         188.0  46.0     1.0    1.0  \n",
       "2         188.0  46.0     1.0    1.0  \n",
       "3         188.0  46.0     1.0    1.0  \n",
       "4         188.0  46.0     1.0    1.0  \n",
       "...         ...   ...     ...    ...  \n",
       "1412860   173.0  18.0     0.0   13.0  \n",
       "1412861   173.0  18.0     0.0   13.0  \n",
       "1412862   173.0  18.0     0.0   13.0  \n",
       "1412863   173.0  18.0     0.0   13.0  \n",
       "1412864   173.0  18.0     0.0   13.0  \n",
       "\n",
       "[1412865 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_id : [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0]\n",
      "activity_id : [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "n_classes : 6\n"
     ]
    }
   ],
   "source": [
    "subject_id = sorted(list(dataset['id'].unique()))\n",
    "activity_id = sorted(list(dataset['act'].unique()))\n",
    "n_classes = len(activity_id)\n",
    "print('subject_id :',subject_id)\n",
    "print('activity_id :',activity_id)\n",
    "print('n_classes :',n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 사람, activity 별로 묶는 코드\n",
    "fdata = []\n",
    "for i in range(len(subject_id)):\n",
    "    data2 = dataset[(dataset['id'] == subject_id[i])]\n",
    "    for j in range(len(activity_id)):\n",
    "        data3 = data2[(dataset['act'] == activity_id[j])]\n",
    "        fdata.append(data3.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5105, 13), (14074, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(fdata[0]), np.shape(fdata[143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample_crop = 100\n",
    "\n",
    "vdatac = [[] for i in range(n_classes)]\n",
    "vlabelc =[[] for i in range(n_classes)] \n",
    "    \n",
    "for i in range(len(fdata)):  #len(fdata)\n",
    "    if len(fdata[i]) > nsample_crop:\n",
    "        window_num = len(fdata[i])//nsample_crop\n",
    "        for k in range(window_num):\n",
    "            start = nsample_crop * k\n",
    "            end = nsample_crop * (k+1)\n",
    "            #print(k, start, end)\n",
    "            vdata_temp = fdata[i][start:end, :6]  #[2:20]\n",
    "            vlabel_temp = fdata[i][start:end, 6:7][0][0]\n",
    "            for j in range(n_classes):\n",
    "                if vlabel_temp == j:\n",
    "                    vdatac[j].append(vdata_temp)\n",
    "                    vlabelc[j].append(convert_to_one_hot(int(vlabel_temp), n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 down_stairs ---> (1307, 100, 6) (1307, 6)\n",
      "1 up_stairs ---> (1562, 100, 6) (1562, 6)\n",
      "2 walking ---> (3433, 100, 6) (3433, 6)\n",
      "3 jogging ---> (1331, 100, 6) (1331, 6)\n",
      "4 standing ---> (3051, 100, 6) (3051, 6)\n",
      "5 sitting ---> (3375, 100, 6) (3375, 6)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_classes):\n",
    "    vdatac[i] = np.array(vdatac[i])\n",
    "    print(i, class_name[i], '--->',np.shape(vdatac[i]), np.shape(vlabelc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 down_stairs --> 43.6 min /  0.73 hrs\n",
      "1 up_stairs --> 52.1 min /  0.87 hrs\n",
      "2 walking --> 114.4 min /  1.91 hrs\n",
      "3 jogging --> 44.4 min /  0.74 hrs\n",
      "4 standing --> 101.7 min /  1.7 hrs\n",
      "5 sitting --> 112.5 min /  1.88 hrs\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_classes):\n",
    "    temp = np.shape(vdatac[i])[0]\n",
    "    print(i, class_name[i],'-->', round(temp*nsample_crop*20/1000/60, 1), 'min / ', round(temp*nsample_crop*20/1000/60/60, 2), 'hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_time_series_data(datas):\n",
    "    length = np.shape(datas[0])[1]\n",
    "    dim = np.shape(datas[0])[2]\n",
    "    # Combine all the data\n",
    "    all_data = np.concatenate(datas, axis=0)\n",
    "    all_data = all_data.reshape(-1, dim)\n",
    "    \n",
    "    # Initialize a StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit the scaler to the data and scale it\n",
    "    all_data = scaler.fit_transform(all_data)\n",
    "\n",
    "    # Initialize an empty list to store the start indices of each class\n",
    "    start_indices = [0]\n",
    "\n",
    "    # Calculate the start index of each class\n",
    "    for data in datas:\n",
    "        start_indices.append(start_indices[-1] + len(data))\n",
    "\n",
    "    all_data = all_data.reshape(-1, length, dim)\n",
    "    # Split the combined data into the original classes\n",
    "    scaled_datas = [all_data[start_indices[i]:start_indices[i+1]] for i in range(len(start_indices)-1)]\n",
    "\n",
    "    return scaled_datas, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "datac_all_norm, scaler = scale_time_series_data(vdatac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled data...\n"
     ]
    }
   ],
   "source": [
    "print('Shuffled data...')\n",
    "for i in range(n_classes):\n",
    "    np.random.shuffle(datac_all_norm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data_and_labels(datas, labels, test_size=0.2):\n",
    "    data_train = []\n",
    "    data_test = []\n",
    "    labels_train = []\n",
    "    labels_test = []\n",
    "\n",
    "    for data, label in zip(datas, labels):\n",
    "        data_tr, data_te, label_tr, label_te = train_test_split(data, label, test_size=test_size, random_state=42)\n",
    "        data_train.append(data_tr)\n",
    "        data_test.append(data_te)\n",
    "        labels_train.append(label_tr)\n",
    "        labels_test.append(label_te)\n",
    "\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, labels_train, labels_test = split_data_and_labels(datac_all_norm, vlabelc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1045, 100, 6) (262, 100, 6)\n",
      "(1249, 100, 6) (313, 100, 6)\n",
      "(2746, 100, 6) (687, 100, 6)\n",
      "(1064, 100, 6) (267, 100, 6)\n",
      "(2440, 100, 6) (611, 100, 6)\n",
      "(2700, 100, 6) (675, 100, 6)\n"
     ]
    }
   ],
   "source": [
    "sz_train = []\n",
    "sz_test = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    print(np.shape(data_train[i]), np.shape(data_test[i]))\n",
    "    sz_train.append(len(data_train[i]))\n",
    "    sz_test.append(len(data_test[i]))\n",
    "    if i == 0:\n",
    "        trainX = data_train[i]\n",
    "        trainy = labels_train[i]\n",
    "        \n",
    "        testX = data_test[i]\n",
    "        testy = labels_test[i]\n",
    "    else:\n",
    "        trainX   = np.vstack((trainX, data_train[i]))\n",
    "        trainy = np.vstack((trainy, labels_train[i]))\n",
    "        \n",
    "        testX   = np.vstack((testX, data_test[i]))\n",
    "        testy = np.vstack((testy, labels_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11244, 100, 6)\n",
      "(11244, 6)\n",
      "(2815, 100, 6)\n",
      "(2815, 6)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(trainX))\n",
    "print(np.shape(trainy))\n",
    "print(np.shape(testX))\n",
    "print(np.shape(testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadFromPickle = False  #True #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../pickle/MotionSense/MotionSense_class6_len100_pub_23.pickle\n",
      "-------------------------------------------\n",
      "# Saved files for publication\n",
      " ---> \n",
      "../pickle/MotionSense/MotionSense_class6_len100_pub_23.pickle\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "outdir_pickle = '../pickle/MotionSense'\n",
    "fn_pickle_pub = '{}/MotionSense_class{}_len{}_pub_23.pickle'.format(outdir_pickle, n_classes, nsample_crop)\n",
    "print(fn_pickle_pub)\n",
    "\n",
    "if not os.path.exists(outdir_pickle):\n",
    "    os.mkdir(outdir_pickle)\n",
    "\n",
    "\n",
    "if loadFromPickle:\n",
    "    if os.path.exists(fn_pickle_pub):\n",
    "        print('{} exists....OK'.format(fn_pickle_pub))\n",
    "    else:\n",
    "        print('{} does NOT exists....'.format(fn_pickle_pub))\n",
    "        loadFromPickle = False\n",
    "        print('loadFromPickle....{}'.format(loadFromPickle))\n",
    "        \n",
    "\n",
    "if not loadFromPickle:\n",
    "    datasave = [None] * 9\n",
    "    datasave[0] = trainX\n",
    "    datasave[1] = trainy\n",
    "    datasave[2] = testX\n",
    "    datasave[3] = testy\n",
    "    datasave[4] = class_name\n",
    "    datasave[5] = feature_name\n",
    "    datasave[6] = scaler\n",
    "    datasave[7] = sz_train\n",
    "    datasave[8] = sz_test\n",
    "\n",
    "    file = open(fn_pickle_pub, 'wb')\n",
    "    pickle.dump(datasave, file)\n",
    "    file.close()\n",
    "\n",
    "    print('-------------------------------------------')\n",
    "    print('# Saved files for publication\\n ---> \\n{}'.format(fn_pickle_pub)) \n",
    "    print('-------------------------------------------')\n",
    "\n",
    "else:\n",
    "    print('load from pickle files')\n",
    "    file = open(fn_pickle_pub, 'rb')\n",
    "    data = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    trainX = data[0]\n",
    "    trainy = data[1]  \n",
    "    testX = data[2]  \n",
    "    testy = data[3] \n",
    "    class_name_pub = data[4] \n",
    "    feature_name = data[5]\n",
    "    scaler = data[6]\n",
    "    sz_train = data[7]\n",
    "    sz_test = data[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 시각화\n",
    "# f, ax = plt.subplots(n_classes, 1, figsize=(8,8), squeeze=False, sharex=True)\n",
    "# for i in range(n_classes):\n",
    "#     ax[i//1, i%1].plot(data_train[i][200])\n",
    "#     ax[i//1, i%1].set_title('{}'.format(class_name[i]))\n",
    "# plt.tight_layout(pad=0.3)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
